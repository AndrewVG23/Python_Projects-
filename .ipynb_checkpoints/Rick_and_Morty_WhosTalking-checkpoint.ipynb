{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"image.JPG\" style=\"width: 200px;\"/>\n",
    "\n",
    "![image.png](attachment:image.png =100x100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Documents'\n",
      "/Users/andrewvangilder/Documents\n"
     ]
    }
   ],
   "source": [
    "cd Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore the vocabularies of the characters in the animated series \"Rick and Morty\". Eventually, I would like to be able to identify a character based on a short snippet of dialogue. \n",
    "\n",
    "I have obtained some transcripts from the Rick and Morty wikia(http://rickandmorty.wikia.com/) and will determine which words in each character's vocabulary are most unique to them based on term tf-idf (frequency-inverse document frequency). This method is commonly utilized by search engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import os\n",
    "import nltk   \n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "\n",
    "from gensim import corpora\n",
    "from collections import Counter\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/andrewvangilder/Desktop/Python/Rick_And_Morty_Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make list of script files\n",
    "\n",
    "scripts = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            scripts.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A_Rickle_in_Time_Transcript.txt',\n",
       " 'Anatomy_Park_transcript.txt',\n",
       " 'Auto_Erotic_Assimilation_Transcript.txt',\n",
       " 'Close_Rick-counters_of_the_Rick_Kind_Transcript.txt',\n",
       " 'Get_Schwifty_Transcript.txt',\n",
       " 'M._Night_Shaym_Aliens_transcript.txt',\n",
       " 'Meeseeks_and_Destroy_Transcript.txt',\n",
       " 'Mortynight_Run_Transcript.txt',\n",
       " 'Rick_Potion_9_Transcript.txt',\n",
       " 'Rixty_Minutes_Transcript.txt',\n",
       " 'Something_Ricked_This_Way_Comes_Transcript.txt',\n",
       " 'The_Rickshank_Rickdemption_Transcript.txt',\n",
       " 'Total_Rickall_Transcript.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#two methods for combining all scripts into one text\n",
    "\n",
    "chunky_text = []\n",
    "chunky_text_lines = []\n",
    "\n",
    "for i in range(0,len(scripts)):\n",
    "    with open(scripts[i]) as doc:\n",
    "        chunky_text.append(nltk.word_tokenize(doc.read()))\n",
    "        \n",
    "        \n",
    "for i in range(0,len(scripts)):\n",
    "    with open(scripts[i]) as doc:\n",
    "        chunky_text_lines.append(''.join(doc.readlines()))\n",
    "        \n",
    "#print(chunky_text_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorting and cleaning scripts into lists of each character's lines\n",
    "#\n",
    "#\n",
    "\n",
    "morty_lines = []\n",
    "rick_lines = []\n",
    "summer_lines = []\n",
    "jerry_lines = []\n",
    "\n",
    "morty_words = []\n",
    "rick_words = []\n",
    "summer_words = []\n",
    "jerry_words = []\n",
    "\n",
    "\n",
    "for i in range(0,len(chunky_text_lines)):\n",
    "    for match in re.finditer(\"Morty:\"+\".*\", chunky_text_lines[i]):\n",
    "        morty_lines.append(chunky_text_lines[i][int(match.start()):int(match.end())])\n",
    "\n",
    "    for match in re.finditer(\"Rick:\"+\".*\", chunky_text_lines[i]):\n",
    "        rick_lines.append(chunky_text_lines[0][int(match.start()):int(match.end())])\n",
    "\n",
    "    for match in re.finditer(\"Summer:\"+\".*\", chunky_text_lines[i]):\n",
    "        summer_lines.append(chunky_text_lines[i][int(match.start()):int(match.end())])\n",
    "        \n",
    "    for match in re.finditer(\"Jerry:\"+\".*\", chunky_text_lines[i]):\n",
    "        jerry_lines.append(chunky_text_lines[i][int(match.start()):int(match.end())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean out the stage directions, found in parentheses \n",
    "#Also make list of words each character uses \n",
    "\n",
    "\n",
    "for i in range(0,len(morty_lines)):\n",
    "    morty_lines[i] = re.sub(\"\\((?<=\\().*(?=\\))\"+\"\\)\",'',morty_lines[i])\n",
    "    morty_words.extend(re.split(r'[\\*\\?\\.\\,!\" \"]', morty_lines[i]))\n",
    "    \n",
    "for i in range(0,len(rick_lines)):\n",
    "    rick_lines[i] = re.sub(\"\\((?<=\\().*(?=\\))\"+\"\\)\",'',rick_lines[i])\n",
    "    rick_lines[i] = re.sub(\"\\\\n\",'',rick_lines[i])\n",
    "    rick_words.extend(re.split(r'[\\*\\?\\.\\,!\" \"]', rick_lines[i]))\n",
    "    \n",
    "for i in range(0,len(summer_lines)):\n",
    "    summer_lines[i] = re.sub(\"\\((?<=\\().*(?=\\))\"+\"\\)\",'',summer_lines[i])\n",
    "    summer_words.extend(re.split(r'[\\*\\?\\.\\,!\" \"]', summer_lines[i]))\n",
    "    \n",
    "for i in range(0,len(jerry_lines)):\n",
    "    jerry_lines[i] = re.sub(\"\\((?<=\\().*(?=\\))\"+\"\\)\",'',jerry_lines[i])\n",
    "    jerry_words.extend(re.split(r'[\\*\\?\\.\\,!\" \"]', jerry_lines[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of words to clean out of characters' vocabularies\n",
    "\n",
    "#words_to_clean = list(string.punctuation) + list(string.ascii_lowercase) + characters + nltk.corpus.stopwords.words(\"english\") + [ \"'ve\",'‘','”','“','``',\"''\",'’','\\'s','n\\'t','\\'re','\\'m','--','...','1']\n",
    "\n",
    "words_to_clean = ['','morty:','rick:','summer:','jerry:','[',']']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning the above words out from characters' vocabularies\n",
    "\n",
    "morty_words = [word.lower() for word in morty_words if word.lower() not in words_to_clean]\n",
    "rick_words = [word.lower() for word in rick_words if word.lower() not in words_to_clean]\n",
    "summer_words = [word.lower() for word in summer_words if word.lower() not in words_to_clean]\n",
    "jerry_words = [word.lower() for word in jerry_words if word.lower() not in words_to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constructing Counter objects to make use of dictionaries and sorting\n",
    "\n",
    "morty_counter = Counter(morty_words)\n",
    "rick_counter = Counter(rick_words)\n",
    "summer_counter = Counter(summer_words)\n",
    "jerry_counter = Counter(jerry_words)\n",
    "\n",
    "#jerry_counter.most_common()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\fract{1+log(f_{t,d})log\\frac{N}{n_{term}}}{1+log(f_{t,c})log\\frac{N}{n_{term}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constructing dictionaries where (key=word in a character's vocabulary) (value=frequency of said word)\n",
    "\n",
    "morty_dictionary = dict(morty_counter)\n",
    "rick_dictionary = dict(rick_counter)\n",
    "summer_dictionary = dict(summer_counter)\n",
    "jerry_dictionary = dict(jerry_counter)\n",
    "\n",
    "#morty_counter.most_common()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#morty_dictionary['go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions to return relative term frequency (tf)\n",
    "\n",
    "def tf(dictionary,term):\n",
    "    corpus_len = 0\n",
    "    \n",
    "    for key in dictionary:\n",
    "        corpus_len += dictionary[key]\n",
    "    return dictionary[term]/corpus_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_dict(dictionary):\n",
    "    corpus_len = 0\n",
    "    tf_dict = {}\n",
    "    \n",
    "    for key in dictionary:\n",
    "        corpus_len += dictionary[key]\n",
    "    for key in dictionary:\n",
    "        tf_dict[key] = dictionary[key]/corpus_len\n",
    "        \n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to return smoothed inverse document frequency (smoothed idf)\n",
    "\n",
    "def idf(word,*args):\n",
    "    \n",
    "    dictionary_list = []\n",
    "    doc_count = 0\n",
    "    \n",
    "    for arg in args:\n",
    "        dictionary_list.append(arg)\n",
    "        if word in arg:\n",
    "            doc_count += 1\n",
    "    \n",
    "    return log((1.1+doc_count)/len(dictionary_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make dictionaries with (key=word in a character's vocab) (value=tf/idf for that word)\n",
    "\n",
    "def tf_idf_dicts(*args):\n",
    "    \n",
    "    tf_idf_dict_list = []\n",
    "    \n",
    "    for arg in args:\n",
    "        tf_idf_dict = {}\n",
    "        for key in tf_dict(arg):\n",
    "            tf_idf_dict[key] = tf_dict(arg)[key]*idf(key,*args)\n",
    "        tf_idf_dict_list.append(tf_idf_dict)\n",
    "        \n",
    "    return tf_idf_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_dict_list = tf_idf_dicts(rick_dictionary, morty_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_dict(morty_dictionary)[key]\n",
    "\n",
    "#tf_idf_dict_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('were', 0.0006742383552787005),\n",
       " ('talking', 0.0006742383552787005),\n",
       " ('morty', 0.0006742383552787005),\n",
       " ('take', 0.0006742383552787005),\n",
       " ('sure', 0.0006742383552787005),\n",
       " ('more', 0.0007866114144918172),\n",
       " ('over', 0.0007866114144918172),\n",
       " ('them', 0.0007866114144918172),\n",
       " ('because', 0.0007866114144918172),\n",
       " ('going', 0.0007866114144918172),\n",
       " ('people', 0.0007866114144918172),\n",
       " ('easy', 0.0007866114144918172),\n",
       " ('time', 0.0008989844737049339),\n",
       " ('from', 0.0008989844737049339),\n",
       " ('or', 0.0008989844737049339),\n",
       " ('would', 0.0008989844737049339),\n",
       " ('back', 0.0008989844737049339),\n",
       " (\"i'm\", 0.0008989844737049339),\n",
       " ('make', 0.0008989844737049339),\n",
       " ('his', 0.0010113575329180509),\n",
       " ('geez', 0.0010113575329180509),\n",
       " ('got', 0.0010113575329180509),\n",
       " ('can', 0.0010113575329180509),\n",
       " ('there', 0.0010113575329180509),\n",
       " (\"you're\", 0.0010113575329180509),\n",
       " ('they', 0.0010113575329180509),\n",
       " ('help', 0.0010113575329180509),\n",
       " ('gun', 0.0010113575329180509),\n",
       " ('how', 0.0011237305921311675),\n",
       " ('huh', 0.0011237305921311675),\n",
       " ('hell', 0.0011237305921311675),\n",
       " ('come', 0.0011237305921311675),\n",
       " ('doing', 0.0012361036513442844),\n",
       " ('our', 0.0012361036513442844),\n",
       " ('mean', 0.0012361036513442844),\n",
       " ('did', 0.0012361036513442844),\n",
       " ('why', 0.0012361036513442844),\n",
       " ('god', 0.0012361036513442844),\n",
       " ('okay', 0.0012361036513442844),\n",
       " ('want', 0.0012361036513442844),\n",
       " ('if', 0.001348476710557401),\n",
       " ('thing', 0.001348476710557401),\n",
       " (\"don't\", 0.0014608497697705177),\n",
       " ('could', 0.0014608497697705177),\n",
       " ('uh', 0.0015732228289836343),\n",
       " ('well', 0.0015732228289836343),\n",
       " ('summer', 0.0016855958881967512),\n",
       " ('one', 0.0016855958881967512),\n",
       " ('whoa', 0.0016855958881967512),\n",
       " ('be', 0.0017979689474098678),\n",
       " ('really', 0.0017979689474098678),\n",
       " ('up', 0.0017979689474098678),\n",
       " ('hey', 0.0017979689474098678),\n",
       " ('but', 0.0017979689474098678),\n",
       " ('out', 0.0017979689474098678),\n",
       " ('here', 0.0017979689474098678),\n",
       " ('at', 0.0017979689474098678),\n",
       " ('dad', 0.0019103420066229845),\n",
       " ('your', 0.0019103420066229845),\n",
       " ('yeah', 0.0019103420066229845),\n",
       " ('go', 0.0019103420066229845),\n",
       " ('gonna', 0.0020227150658361018),\n",
       " ('think', 0.0020227150658361018),\n",
       " ('not', 0.002135088125049218),\n",
       " ('on', 0.002135088125049218),\n",
       " ('was', 0.002135088125049218),\n",
       " ('man', 0.002135088125049218),\n",
       " ('so', 0.002135088125049218),\n",
       " ('for', 0.002247461184262335),\n",
       " ('right', 0.002247461184262335),\n",
       " ('like', 0.002247461184262335),\n",
       " ('get', 0.002472207302688569),\n",
       " ('have', 0.0025845803619016852),\n",
       " ('he', 0.0025845803619016852),\n",
       " ('with', 0.0025845803619016852),\n",
       " ('about', 0.0029216995395410354),\n",
       " ('just', 0.0030340725987541522),\n",
       " ('this', 0.0030340725987541522),\n",
       " ('do', 0.0030340725987541522),\n",
       " ('in', 0.0031464456579672687),\n",
       " ('we', 0.0033711917763935024),\n",
       " ('are', 0.0033711917763935024),\n",
       " ('no', 0.0033711917763935024),\n",
       " ('all', 0.0033711917763935024),\n",
       " ('is', 0.0034835648356066192),\n",
       " ('my', 0.0035959378948197357),\n",
       " ('me', 0.0040454301316722036),\n",
       " ('of', 0.004270176250098436),\n",
       " ('it', 0.005056787664590254),\n",
       " ('oh', 0.005056787664590254),\n",
       " ('and', 0.005281533783016487),\n",
       " ('know', 0.005955772138295188),\n",
       " ('what', 0.006180518256721421),\n",
       " ('that', 0.007079502730426355),\n",
       " ('to', 0.009214590855475572),\n",
       " ('a', 0.00966408309232804),\n",
       " ('the', 0.010338321447606741),\n",
       " ('i', 0.011124932862098558),\n",
       " ('rick', 0.011124932862098558),\n",
       " ('you', 0.019103420066229847)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The beginning of the list is populated with words unique to the selected character\n",
    "#in comparison to the other characters queried.\n",
    "\n",
    "#The end of the list contains words that are common for all characters in the \"tf_idf_dicts\" arguments list\n",
    "\n",
    "\n",
    "sorted_tf_idf_morty = sorted(tf_idf_dict_list[1].items(), key=operator.itemgetter(1))\n",
    "\n",
    "sorted_tf_idf_morty[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idf('ricks',rick_dictionary,morty_dictionary,jerry_dictionary,summer_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.1 |Anaconda 4.4.0 (x86_64)| (default, May 11 2017, 13:04:09) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
